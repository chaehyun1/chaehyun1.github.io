---
layout: archive
title: "The normal model"
categories:
  - bayes
use_math: true
---


## Week 3 + $\alpha$

<br>교재: FCB  

5.1 The normal model
----------------------
\begin{equation}
p(y|\theta, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{1}{2}(\frac{y-\theta}{\sigma})^2}, \quad -\infty < y < \infty
\nonumber
\end{equation}
$Y$의 density가 위와 같은 경우, random variable $Y$는 평균이 $\theta$이고, 분산이 $\sigma^2$ 정규 분포를 따른다.  

<br>Example: women's height
--------------------
1893년부터 1898년까지 English families에 대한 연구는 18세 이상의 1375명의 여성에 대한 키 데이터를 모았다.  
$n = 1375,\quad \bar{y} = 63.75, s = 2.62$  
여성들 키의 변동성의 원인은 유전, 다이어트, 병, 스트레스 등 인간의 성장을 컨트롤하는 요소들이 개인마다 다르기 때문이다. 이러한 요인들의 변동성은 그들의 키의 변동성에 영향을 주었다.    
Let $y_i$ be the height in inches of women $i$, a simple additive model for height might be
\begin{equation}
y_n = a + b \times gene_n + c \times diet_n + d \times disease_n + ...
\nonumber
\end{equation}
For such situations, the central limit theorem says theat the empirical distribution $y_1, ..., y_n$ will look like a normal distribution, and so the normal model provides an appropriate sampling model for the data.  
![SmartSelectImage_2022-08-12-14-51-28](https://user-images.githubusercontent.com/108905986/184626233-b1c4c961-badd-4258-9772-a32706a5ee46.png)  


<br> 5.2 Inference for the mean, conditional on the variance
----------------------
Suppose {$Y_1, ..., Y_n|\theta, \sigma^2$} ~ i.i.d normal $(\theta, \sigma^2)$.
\begin{equation}
p(y_1, ..., y_n|\theta, \sigma^2) = \prod_{i=1}^{n} p(y_i|\theta, \sigma^2)
\nonumber
\end{equation}

\begin{equation}
= \prod_{i =1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2}(\frac{y_i-\theta}{\sigma})^2}
\nonumber
\end{equation}

\begin{equation}
= (2\pi\sigma^2)^{-n/2}exp\{-\frac{1}{2}\sum(\frac{y_i-\theta}{\sigma})^2\}
\nonumber
\end{equation}

exponent 안의 quadratic form을 정리하면, $p(y_1, ..., y_n|\theta, \sigma^2)$은
begin{equation}
\sum(\frac{y_i-\theta}{\sigma})^2 = \frac{1}{sigma^2} \sum{y_i}^2 - 2\frac{\theta}{\sigma^2}\sigma{y_i} + n\frac{\theta^2}{\sigma^2} 
\nonumber
end{equation}

여기서 $\sum{y_i}^2$와 $\sum{y_i}$은 sufficient statistic이다. 이 두 가지의 값을 아는 것은 $\bar{y} = \sum{y_i}/n$과 $s^2 = \sum{(y_i-\bar{y})^2}/(n-1)$의 값을 아는 것과 동일하며, 여기서 $\bar{y}$와 $s^2$ 또한 sufficient statistc이다.   

<br>우리는 $\sigma^2$를 알 때 $\theta$에 대한 추론을 $\theta$에 대한 conjugate prior dist을 이용하여 구할 것이다. 
\begin{equation}
p(\theta|y_1, ..., y_n, \sigma^2) \propto p(\theta|\sigma^2) \times e^{-\frac{1}{2\sigma^2}\sum{(y_i-\theta)^2}}
\nonumber
\end{equation}
이 식은 다시 $\propto p(\theta|\sigma^2) \times e^{c_1(\theta-c_2)^2}$으로 나타낼 수 있다.  
만약 사후 분포가 같은 계열에 속한다면, 사전 분포에 대한 계열은 샘플링 모델과 conjugate이다. 위의 식에서, 만약 $p(\theta|\sigma^2)$가 conjugate라면, $p(\theta|\sigma^2)$은 $e^{c_1(\theta-c_2)^2}$과 같은 이차 형식을 포함해야 한다. 이러한 계열의 가장 간단한 형태가 normal family of densities이기 때문에, 만약 $p(\theta|\sigma^2)$이 normal이고 $y_1,..., y_n$이 i.i.d. norma($\theta, \sigma^2$)을 따르면, $p(\theta|y_1, ..., y_n, \sigma^2)$은 또한 normal density를 가진다. 만약 $\theta \sim$ normal $(\mu_0, \tau_0^2)$이라면,
\begin{equation}
p(\theta|y_1, ..., y_n, \sigma^2) \propto p(\theta|\sigma^2) p(y_1, ..., y_n|\theta, \sigma^2)
\nonumber
\end{equation}

\begin{equation}
\propto exp\{-\frac{1}{2\tau_0^2}(\theta-\mu_0)^2 \} exp\{-\frac{1}{2\sigma^2}\sum{(y_i-\theta)^2} \}
\nonumber
\end{equation}
위 식에서 exponent 안의 $-\frac{1}{2}$는 무시하고 정리해보면 $a\theta^2 -2b\theta + c$의 형태를 가지는데, $a=\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}, \quad b = \frac{\mu_0}{\tau_n^2} + \frac{\sum{y_i}}{\sigma^2}$, and $c = c(\mu_0, \tau_0^2, \sigma^2, y_1, ..., y_n)$이다.

\begin{equation}
p(\theta|\sigma^2, y_1, ..., y_n) \propto exp\{-\frac{1}{2}(a\theta^2 - 2b\theta)\} = exp\{-\frac{1}{2}a(\theta^2 - 2b\theta/a + b^2/a^2) + \frac{1}{2}b^2/a\}
\nonumber
\end{equation}

\begin{equation}
\propto exp\{-\frac{1}{2}a(\theta - b/a)^2\} = exp\{-\frac{1}{2}(\frac{\theta-b/a}{1/\sqrt{a}})^2 \}
\nonumber
\end{equation}

위 식은 정규분포와 같은 모양을 가지는데, $\frac{1}{\sqrt{a}}$는 standard deviation이고, $\frac{b}{a}$은 평균의 역할을 한다. 확률 분포는 그것의 모양으로 결정되기 때문에, $p(\theta |\sigma^2, y_1, ..., y_n)$은 실제로 normal density이다. 이러한 density의 평균과 분산을 각각 $\mu_n, \tau_n^2$으로 나타낸다. 
\begin{equation}
\tau_n^2 = \frac{1}{a} = \frac{1}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}, \quad  \mu_n = \frac{b}{a} = \frac{\frac{1}{\tau_0^2}\mu_0 + \frac{n}{\sigma^2}\bar{y}}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}
\nonumber
\end{equation}  

<br> Combining information
------------------------
Posterior variance and precision: $\frac{1}{\tau_n^2} = \frac{1}{\tau_0^2}+ \frac{n}{\sigma^2}$  
- 분산의 역수 형태를 precision이라고 한다.  
$\tilde{\sigma^2} = 1/\sigma^2$: sampling precision, how close the $y_i$'s are to $\theta$  
$\tilde{\tau_0^2} = 1/\tau_0^2$: prior precision  
$\tilde{\tau_0^2} = 1/\tau_0^2$: posterior precision  
<br>
정규모델에서,
\begin{equation}
\tilde{\tau_n^2} = \tilde{\tau_0^2} + n\tilde{\sigma^2}
\nonumber
\end{equation}
- posterior info = prior info + data info  
<br>
\begin{equation}
\mu_n = \frac{\frac{\tilde{\tau_0^2}}{\tilde{\tau_0^2} + n\tilde{\sigma^2}}\mu_0 + \frac{n\tilde{\sigma^2}}{\tilde{\tau_0^2}+ \tilde{\sigma^2}} \bar{y}
\nonumber
\end{equation}  
- 사후 평균은 사전 평균과 샘플 평균의 가중평균이다. 만약 사전 평균 $\mu_0$가 $Y_1, ..., Y_n$의 같은 (또는 비슷한) 모집단으로부터의 $k_0$ 사전 observations에 근거한다면, $\tau_0^2 = \sigma^2 / k_0$으로 나타낸다. 따라서
\begin{equation}
\mu_n = \frac{k_0}{k_0 + n}\mu_0 + \frac{n}{k_0+n}} \bar{y}
\nonumber
\end{equation}  
 
<br>Prediction
-----------
